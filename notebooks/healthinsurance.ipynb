{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2ae39b7",
   "metadata": {},
   "source": [
    "##  Health Insurance Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355997e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "class HealthInsurance:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Definindo o caminho dos arquivos do projeto\n",
    "        self.home_path = 'C:\\\\Users\\\\raquel\\\\Documents\\\\Comunidade DS\\\\repos\\\\06-PA-Health-Insurance-Cross-Sell\\\\health_insurance_ross_sell\\\\'\n",
    "        \n",
    "        # Carregando os objetos scaler gerados no treinamento do modelo\n",
    "        self.annual_premium_scaler =            pickle.load(open(self.home_path + 'src\\\\features\\\\annual_premium_scaler.pkl', 'rb'))\n",
    "        self.age_scaler =                       pickle.load(open(self.home_path + 'src\\\\features\\\\age_scaler.pkl', 'rb')) \n",
    "        self.vintage_scaler =                   pickle.load(open(self.home_path + 'src\\\\features\\\\vintage_scaler.pkl', 'rb')) \n",
    "        self.target_encode_gender_scaler =      pickle.load(open(self.home_path + 'src\\\\features\\\\target_encode_gender_scaler.pkl', 'rb'))\n",
    "        self.target_encode_region_code_scaler = pickle.load(open(self.home_path + 'src\\\\features\\\\target_encode_region_code_scaler.pkl', 'rb'))\n",
    "        self.fe_policy_sales_channel_scaler =   pickle.load(open(self.home_path + 'src\\\\features\\\\fe_policy_sales_channel_scaler.pkl', 'rb'))\n",
    "        \n",
    "    def data_cleaning(self, df1):\n",
    "        # 1.1. Renomeando as colunas\n",
    "        cols_new = ['id', 'gender', 'age', 'driving_license', 'region_code', 'previously_insured', 'vehicle_age', \n",
    "                    'vehicle_damage', 'annual_premium', 'policy_sales_channel', 'vintage', 'response']\n",
    "\n",
    "        df1.columns = cols_new\n",
    "        \n",
    "        return df1 \n",
    "\n",
    "    \n",
    "    def feature_engineering(self, df2):\n",
    "        # 2.0. Feature Engineering\n",
    "\n",
    "        # Criando a coluna 'vehicle_damage_num' para representar os veículos que já foram danificados (1) e os que não foram danificados (0)\n",
    "        df2['vehicle_damage'] = df2['vehicle_damage'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "        # Transformando a coluna 'vehicle_age' em uma coluna categórica para aplicação de técnicas de codificação\n",
    "        df2['vehicle_age'] =  df2['vehicle_age'].apply(lambda x: 'over_2_years' if x == '> 2 Years' else 'between_1_2_year' if x == '1-2 Year' else 'below_1_year')\n",
    "        \n",
    "        return df2\n",
    "    \n",
    "    \n",
    "    def data_preparation(self, df5):\n",
    "        # Aplicando a transformação de Escalonamento Padrão na coluna 'annual_premium'\n",
    "        df5['annual_premium'] = self.annual_premium_scaler.transform(df5[['annual_premium']].values)\n",
    "\n",
    "        # Aplicando a transformação de Escalonamento Mínimo e Máximo na coluna 'age'\n",
    "        df5['age'] = self.age_scaler.transform(df5[['age']].values)\n",
    "\n",
    "        # Aplicando a transformação de Escalonamento Mínimo e Máximo na coluna 'vintage'\n",
    "        df5['vintage'] = self.vintage_scaler.transform(df5[['vintage']].values)\n",
    "\n",
    "        # Codificando a coluna 'gender' utilizando a técnica de Target Encoding\n",
    "        df5.loc[:, 'gender'] = df5['gender'].map(self.target_encode_gender)\n",
    "\n",
    "        # Aplica o processo de target encoding na coluna region_code\n",
    "        df5.loc[:, 'region_code'] = df5['region_code'].map(self.target_encode_region_code)\n",
    "\n",
    "        # Cria variáveis dummy para a coluna vehicle_age usando a função pd.get_dummies\n",
    "        df5 = pd.get_dummies(df5, prefix='vehicle_age', columns=['vehicle_age'])\n",
    "\n",
    "        # Aplica o processo de frequency encoding na coluna policy_sales_channel\n",
    "        df5.loc[:, 'policy_sales_channel'] = df5['policy_sales_channel'].map(self.fe_policy_sales_channel)\n",
    "\n",
    "        # Feature Selection\n",
    "        # Seleciona as colunas relevantes para o modelo\n",
    "        cols_selected = ['annual_premium', 'vintage', 'age', 'region_code', 'vehicle_damage', 'previously_insured', 'policy_sales_channel']\n",
    "\n",
    "        # Retorna o dataframe com as colunas selecionadas\n",
    "        return df5[cols_selected]\n",
    "\n",
    "\n",
    "    def get_prediction(self, model, original_data, test_data):\n",
    "        # model prediction\n",
    "        # Usa o modelo treinado para fazer as predições em test_data\n",
    "        pred = model.predict_proba(test_data)\n",
    "        \n",
    "        # join prediction into original data\n",
    "        # Adiciona as predições ao dataframe original\n",
    "        original_data['prediction'] = pred\n",
    "        \n",
    "        # Retorna o dataframe em formato JSON\n",
    "        return original_data.to_json(orient='records', date_format='iso')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
